{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import  InputLayer, Conv2D, Lambda, Dropout, MaxPooling2D, Conv2DTranspose, concatenate\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from UNet_Fourier_Facilities import Fourier_Images\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1654106464\n"
     ]
    }
   ],
   "source": [
    "print(int(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = tf.keras.models.load_model(\"./cnn_models/single_rgb_image_regression_V02_epochs_100_1653595623\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_cnn = tf.keras.models.load_model(\"./models/single_rgb_image\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img1 = Image.open(\n",
    "#     \"D:\\Main\\MA_PROGR\\Data\\Train\\LED_Wand_Aufnahmen\\Alias\\LED_Wand_20001.png\")\n",
    "# img1 = np.asarray(img1)/255\n",
    "# img1 = img1.reshape(1, 60, 60, 3)\n",
    "# res1 = model.predict(img1)\n",
    "# print(res1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 42\n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "IMG_CHANNELS = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILMED_PATH = \"D:\\\\Main\\\\MA_PROGR\\\\Data\\\\Train\\\\UNet_Train\\\\model_at_tree_100_pics\\\\filmed\"\n",
    "TRAIN_CLEAN_PATH = \"D:\\\\Main\\\\MA_PROGR\\\\Data\\\\Train\\\\UNet_Train\\\\model_at_tree_100_pics\\\\clean_aligned\"\n",
    "# TEST_PATH = \"./Data/data-science-bowl-2018/stage1_test/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filmed_imgs = []\n",
    "train_clean_imgs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "OFFSET = 200\n",
    "abbruch_idx = 30\n",
    "\n",
    "\n",
    "def my_train_filmed_gen():\n",
    "    for i, addr_filmed in enumerate(os.listdir(TRAIN_FILMED_PATH)):\n",
    "        img =  plt.imread(f\"{TRAIN_FILMED_PATH}\\{addr_filmed}\")\n",
    "        yield img[OFFSET:IMG_WIDTH+OFFSET, OFFSET:IMG_HEIGHT+OFFSET, :3]\n",
    "\n",
    "def my_train_clean_gen():\n",
    "    for i, addr_clean in enumerate(os.listdir(TRAIN_CLEAN_PATH)):\n",
    "        img =  plt.imread(f\"{TRAIN_CLEAN_PATH}\\{addr_clean}\")\n",
    "        yield img[OFFSET:IMG_WIDTH+OFFSET, OFFSET:IMG_HEIGHT+OFFSET, :3]\n",
    "\n",
    "\n",
    "train_filmed_img_gen_obj = my_train_filmed_gen()\n",
    "train_clean_img_gen_obj = my_train_clean_gen()\n",
    "\n",
    "# for i, addr_filmed in enumerate( os.listdir(TRAIN_FILMED_PATH)):\n",
    "#     if i > 5:\n",
    "#         break\n",
    "#     img = plt.imread(f\"{TRAIN_FILMED_PATH}\\{addr_filmed}\")\n",
    "\n",
    "#     # :3 falls es Alpha Channel gibt (der soll weg)\n",
    "#     train_filmed_imgs.append(\n",
    "#         img[OFFSET:IMG_WIDTH+OFFSET, OFFSET:IMG_HEIGHT+OFFSET, :3])\n",
    "\n",
    "# for i , addr_clean in enumerate(os.listdir(TRAIN_CLEAN_PATH)):\n",
    "#     if i > 5:\n",
    "#         break\n",
    "#     # :3 falls es Alpha Channel gibt (der soll weg)\n",
    "#     img = plt.imread(f\"{TRAIN_CLEAN_PATH}\\{addr_clean}\")\n",
    "#     train_clean_imgs.append(\n",
    "#         img[OFFSET:IMG_WIDTH+OFFSET, OFFSET:IMG_HEIGHT+OFFSET, :3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(train_filmed_img_gen_obj.__next__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(train_clean_img_gen_obj.__next__())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(train_clean_imgs[0])\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build U-Net-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_39\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_391 (InputLayer)          [(None, 128, 128, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_39 (Lambda)              (None, 128, 128, 1)  0           input_391[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_741 (Conv2D)             (None, 128, 128, 16) 160         lambda_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_351 (Dropout)           (None, 128, 128, 16) 0           conv2d_741[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_742 (Conv2D)             (None, 128, 128, 16) 2320        dropout_351[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_156 (MaxPooling2D (None, 64, 64, 16)   0           conv2d_742[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_743 (Conv2D)             (None, 64, 64, 32)   4640        max_pooling2d_156[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dropout_352 (Dropout)           (None, 64, 64, 32)   0           conv2d_743[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_744 (Conv2D)             (None, 64, 64, 32)   9248        dropout_352[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_157 (MaxPooling2D (None, 32, 32, 32)   0           conv2d_744[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_745 (Conv2D)             (None, 32, 32, 64)   18496       max_pooling2d_157[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dropout_353 (Dropout)           (None, 32, 32, 64)   0           conv2d_745[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_746 (Conv2D)             (None, 32, 32, 64)   36928       dropout_353[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_158 (MaxPooling2D (None, 16, 16, 64)   0           conv2d_746[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_747 (Conv2D)             (None, 16, 16, 128)  73856       max_pooling2d_158[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dropout_354 (Dropout)           (None, 16, 16, 128)  0           conv2d_747[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_748 (Conv2D)             (None, 16, 16, 128)  147584      dropout_354[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_159 (MaxPooling2D (None, 8, 8, 128)    0           conv2d_748[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_749 (Conv2D)             (None, 8, 8, 256)    295168      max_pooling2d_159[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dropout_355 (Dropout)           (None, 8, 8, 256)    0           conv2d_749[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_750 (Conv2D)             (None, 8, 8, 256)    590080      dropout_355[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_156 (Conv2DTra (None, 16, 16, 128)  131200      conv2d_750[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_156 (Concatenate)   (None, 16, 16, 256)  0           conv2d_transpose_156[0][0]       \n",
      "                                                                 conv2d_748[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_751 (Conv2D)             (None, 16, 16, 128)  295040      concatenate_156[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_356 (Dropout)           (None, 16, 16, 128)  0           conv2d_751[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_752 (Conv2D)             (None, 16, 16, 128)  147584      dropout_356[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_157 (Conv2DTra (None, 32, 32, 64)   32832       conv2d_752[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_157 (Concatenate)   (None, 32, 32, 128)  0           conv2d_transpose_157[0][0]       \n",
      "                                                                 conv2d_746[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_753 (Conv2D)             (None, 32, 32, 64)   73792       concatenate_157[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_357 (Dropout)           (None, 32, 32, 64)   0           conv2d_753[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_754 (Conv2D)             (None, 32, 32, 64)   36928       dropout_357[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_158 (Conv2DTra (None, 64, 64, 32)   8224        conv2d_754[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_158 (Concatenate)   (None, 64, 64, 64)   0           conv2d_transpose_158[0][0]       \n",
      "                                                                 conv2d_744[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_755 (Conv2D)             (None, 64, 64, 32)   18464       concatenate_158[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_358 (Dropout)           (None, 64, 64, 32)   0           conv2d_755[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_756 (Conv2D)             (None, 64, 64, 32)   9248        dropout_358[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_159 (Conv2DTra (None, 128, 128, 16) 2064        conv2d_756[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_159 (Concatenate)   (None, 128, 128, 32) 0           conv2d_transpose_159[0][0]       \n",
      "                                                                 conv2d_742[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_757 (Conv2D)             (None, 128, 128, 16) 4624        concatenate_159[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_359 (Dropout)           (None, 128, 128, 16) 0           conv2d_757[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_758 (Conv2D)             (None, 128, 128, 16) 2320        dropout_359[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_759 (Conv2D)             (None, 128, 128, 1)  17          conv2d_758[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,940,817\n",
      "Trainable params: 1,940,817\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(IMG_WIDTH, IMG_HEIGHT, 1), batch_size=None)\n",
    "\n",
    "# Hier werden Preprocessing-Schritte ausgeführt\n",
    "# s ist hier dann Differnzbild (Pixelraum_Fourier)\n",
    "s = Lambda(lambda x: x / 255)(inputs)\n",
    "\n",
    "\n",
    "# Contraction path\n",
    "c1 = Conv2D(\n",
    "    16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
    "c1 = Dropout(0.1)(c1)\n",
    "c1 = Conv2D(16, (3, 3), activation='relu',\n",
    "            kernel_initializer='he_normal', padding='same')(c1)\n",
    "p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "c2 = Conv2D(32, (3, 3), activation='relu',\n",
    "            kernel_initializer='he_normal', padding='same')(p1)\n",
    "c2 = Dropout(0.1)(c2)\n",
    "c2 = Conv2D(32, (3, 3), activation='relu',\n",
    "            kernel_initializer='he_normal', padding='same')(c2)\n",
    "p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "c3 = Conv2D(64, (3, 3), activation='relu',\n",
    "            kernel_initializer='he_normal', padding='same')(p2)\n",
    "c3 = Dropout(0.2)(c3)\n",
    "c3 = Conv2D(64, (3, 3), activation='relu',\n",
    "            kernel_initializer='he_normal', padding='same')(c3)\n",
    "p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "c4 = Conv2D(128, (3, 3), activation='relu',\n",
    "            kernel_initializer='he_normal', padding='same')(p3)\n",
    "c4 = Dropout(0.2)(c4)\n",
    "c4 = Conv2D(128, (3, 3), activation='relu',\n",
    "            kernel_initializer='he_normal', padding='same')(c4)\n",
    "p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "\n",
    "c5 = Conv2D(256, (3, 3), activation='relu',\n",
    "            kernel_initializer='he_normal', padding='same')(p4)\n",
    "c5 = Dropout(0.3)(c5)\n",
    "c5 = Conv2D(256, (3, 3), activation='relu',\n",
    "            kernel_initializer='he_normal', padding='same')(c5)\n",
    "\n",
    "# Expansive path\n",
    "u6 = Conv2DTranspose(\n",
    "    128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "u6 = concatenate([u6, c4])\n",
    "c6 = Conv2D(128, (3, 3), activation='relu',\n",
    "            kernel_initializer='he_normal', padding='same')(u6)\n",
    "c6 = Dropout(0.2)(c6)\n",
    "c6 = Conv2D(128, (3, 3), activation='relu',\n",
    "            kernel_initializer='he_normal', padding='same')(c6)\n",
    "\n",
    "u7 = Conv2DTranspose(\n",
    "    64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "u7 = concatenate([u7, c3])\n",
    "c7 = Conv2D(64, (3, 3), activation='relu',\n",
    "            kernel_initializer='he_normal', padding='same')(u7)\n",
    "c7 = Dropout(0.2)(c7)\n",
    "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu',\n",
    "                            kernel_initializer='he_normal', padding='same')(c7)\n",
    "\n",
    "u8 = tf.keras.layers.Conv2DTranspose(\n",
    "    32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                            kernel_initializer='he_normal', padding='same')(u8)\n",
    "c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
    "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                            kernel_initializer='he_normal', padding='same')(c8)\n",
    "\n",
    "u9 = tf.keras.layers.Conv2DTranspose(\n",
    "    16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
    "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu',\n",
    "                            kernel_initializer='he_normal', padding='same')(u9)\n",
    "c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
    "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu',\n",
    "                            kernel_initializer='he_normal', padding='same')(c9)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "model_u_net = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "model_u_net.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ppm: postprocessing model \n",
    "\n",
    "def create_postprocessing_model():\n",
    "\n",
    "    ppm_input_img_clean = tf.keras.Input(shape=(128,128, 3), batch_size=1)\n",
    "    ppm_input_img_filmed = tf.keras.Input(shape=(128,128, 3), batch_size=1)\n",
    "    ppm_input_unet_output = tf.keras.Input(shape=(128,128), batch_size=1)\n",
    "\n",
    "    ppm_input_img_clean_complex_r = tf.keras.Input(shape=(128,128), batch_size=1, dtype=tf.complex64)\n",
    "    ppm_input_img_clean_complex_g = tf.keras.Input(shape=(128,128), batch_size=1, dtype=tf.complex64)\n",
    "    ppm_input_img_clean_complex_b = tf.keras.Input(shape=(128,128), batch_size=1, dtype=tf.complex64)\n",
    "\n",
    "    ppm_input_img_filmed_complex_r = tf.keras.Input(shape=(128,128), batch_size=1, dtype=tf.complex64)\n",
    "    ppm_input_img_filmed_complex_g = tf.keras.Input(shape=(128,128), batch_size=1, dtype=tf.complex64)\n",
    "    ppm_input_img_filmed_complex_b = tf.keras.Input(shape=(128,128), batch_size=1, dtype=tf.complex64)\n",
    "\n",
    "\n",
    "\n",
    "    ones = tf.ones((128, 128))\n",
    "    zeros = tf.zeros((128, 128))\n",
    "    ones_t2c = tf.complex(ones, zeros)\n",
    "    u_net_output_t2c = tf.complex(ppm_input_unet_output, zeros)\n",
    "\n",
    "    # FORMEL: (1 - out) * clean + out * filmed\n",
    "    # out == mask \n",
    "    # t2c -> transfered to complex\n",
    "\n",
    "\n",
    "    def soft_blending(clean, filmed, ones_t2c=ones_t2c, u_net_output_t2c=u_net_output_t2c):\n",
    "        zw1 = tf.math.subtract(ones_t2c, u_net_output_t2c)\n",
    "        zw1 = tf.math.multiply(zw1, clean)\n",
    "\n",
    "        zw2 = tf.multiply(u_net_output_t2c, filmed)\n",
    "        return tf.math.add(zw1, zw2)\n",
    "\n",
    "\n",
    "    img_processed_complex_fourier_r = soft_blending(\n",
    "        ppm_input_img_clean_complex_r, ppm_input_img_filmed_complex_r)\n",
    "\n",
    "    img_processed_complex_fourier_g = soft_blending(\n",
    "        ppm_input_img_clean_complex_g, ppm_input_img_filmed_complex_g)\n",
    "\n",
    "    img_processed_complex_fourier_b = soft_blending(\n",
    "        ppm_input_img_clean_complex_b, ppm_input_img_filmed_complex_b)\n",
    "\n",
    "\n",
    "\n",
    "    # # img_processed_px_fourier = tf.math.log(                     # zum anschauen\n",
    "    # #     tf.math.abs(img_processed_complex_fourier_r))\n",
    "\n",
    "    # ----------- INVERSE FOURIER TRANSFORMATION -----------\n",
    "\n",
    "    img_processed_r = tf.signal.ifft2d(\n",
    "        img_processed_complex_fourier_r\n",
    "    )\n",
    "    img_processed_g = tf.signal.ifft2d(\n",
    "        img_processed_complex_fourier_g\n",
    "    )\n",
    "    img_processed_b = tf.signal.ifft2d(\n",
    "        img_processed_complex_fourier_b\n",
    "    )\n",
    "\n",
    "\n",
    "    # 3 Einzelkanäle zu einem RGB Bild\n",
    "    img_processed_r = tf.math.abs(img_processed_r)/255\n",
    "    img_processed_g = tf.math.abs(img_processed_g)/255\n",
    "    img_processed_b = tf.math.abs(img_processed_b)/255\n",
    "\n",
    "    img_processed_rgb = tf.stack(\n",
    "        [img_processed_r, img_processed_g, img_processed_b], axis=3)\n",
    "\n",
    "    postprocess_model = tf.keras.Model(inputs=[\n",
    "        ppm_input_img_clean, \n",
    "        ppm_input_img_filmed,\n",
    "        ppm_input_unet_output,\n",
    "        ppm_input_img_clean_complex_r ,\n",
    "        ppm_input_img_clean_complex_g ,\n",
    "        ppm_input_img_clean_complex_b ,\n",
    "        ppm_input_img_filmed_complex_r, \n",
    "        ppm_input_img_filmed_complex_g,\n",
    "        ppm_input_img_filmed_complex_b\n",
    "    ], outputs=[img_processed_rgb], name=\"postprocessing_model\")\n",
    "\n",
    "    # postprocess_model.summary()\n",
    "    return postprocess_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_postprocessing_model():\n",
    "#     clean = tf.keras.Input(shape=(128, 128, 3), batch_size=1)\n",
    "#     darker = tf.math.multiply(clean, 3)\n",
    "\n",
    "#     postprocessing_model = tf.keras.Model(inputs=[clean], outputs=[darker])\n",
    "\n",
    "#     return postprocessing_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"postprocessing_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_394 (InputLayer)          [(1, 128, 128)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.dtypes.complex_39 (TFOpLambd (1, 128, 128)        0           input_394[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_117 (TFOpLambd (1, 128, 128)        0           tf.dtypes.complex_39[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "input_395 (InputLayer)          [(1, 128, 128)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_398 (InputLayer)          [(1, 128, 128)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_118 (TFOpLambd (1, 128, 128)        0           tf.dtypes.complex_39[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "input_396 (InputLayer)          [(1, 128, 128)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_399 (InputLayer)          [(1, 128, 128)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_119 (TFOpLambd (1, 128, 128)        0           tf.dtypes.complex_39[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "input_397 (InputLayer)          [(1, 128, 128)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_400 (InputLayer)          [(1, 128, 128)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_234 (TFOpLambd (1, 128, 128)        0           tf.math.subtract_117[0][0]       \n",
      "                                                                 input_395[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_235 (TFOpLambd (1, 128, 128)        0           tf.dtypes.complex_39[0][0]       \n",
      "                                                                 input_398[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_236 (TFOpLambd (1, 128, 128)        0           tf.math.subtract_118[0][0]       \n",
      "                                                                 input_396[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_237 (TFOpLambd (1, 128, 128)        0           tf.dtypes.complex_39[0][0]       \n",
      "                                                                 input_399[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_238 (TFOpLambd (1, 128, 128)        0           tf.math.subtract_119[0][0]       \n",
      "                                                                 input_397[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_239 (TFOpLambd (1, 128, 128)        0           tf.dtypes.complex_39[0][0]       \n",
      "                                                                 input_400[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.add_117 (TFOpLambda)    (1, 128, 128)        0           tf.math.multiply_234[0][0]       \n",
      "                                                                 tf.math.multiply_235[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.add_118 (TFOpLambda)    (1, 128, 128)        0           tf.math.multiply_236[0][0]       \n",
      "                                                                 tf.math.multiply_237[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.add_119 (TFOpLambda)    (1, 128, 128)        0           tf.math.multiply_238[0][0]       \n",
      "                                                                 tf.math.multiply_239[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.signal.ifft2d_117 (TFOpLambd (1, 128, 128)        0           tf.math.add_117[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.signal.ifft2d_118 (TFOpLambd (1, 128, 128)        0           tf.math.add_118[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.signal.ifft2d_119 (TFOpLambd (1, 128, 128)        0           tf.math.add_119[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.abs_117 (TFOpLambda)    (1, 128, 128)        0           tf.signal.ifft2d_117[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.abs_118 (TFOpLambda)    (1, 128, 128)        0           tf.signal.ifft2d_118[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.abs_119 (TFOpLambda)    (1, 128, 128)        0           tf.signal.ifft2d_119[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.truediv_117 (TFOpLambda (1, 128, 128)        0           tf.math.abs_117[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.truediv_118 (TFOpLambda (1, 128, 128)        0           tf.math.abs_118[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.truediv_119 (TFOpLambda (1, 128, 128)        0           tf.math.abs_119[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "input_392 (InputLayer)          [(1, 128, 128, 3)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_393 (InputLayer)          [(1, 128, 128, 3)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_39 (TFOpLambda)        (1, 128, 128, 3)     0           tf.math.truediv_117[0][0]        \n",
      "                                                                 tf.math.truediv_118[0][0]        \n",
      "                                                                 tf.math.truediv_119[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "postprocessing_model = create_postprocessing_model()\n",
    "postprocessing_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Train loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calc_mean_alias_value_of_one_image(x_filmed, x_clean):\n",
    "    # print(\"betrete calc_mean_aias_value_of_one_image\")\n",
    "\n",
    "    # print(\"x_filmed: \")\n",
    "    # plt.imshow(x_filmed)\n",
    "    # plt.show()\n",
    "    # print(\"x_clean: \")\n",
    "    # plt.imshow(x_clean)\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    fourier_handler = Fourier_Images(x_filmed, x_clean)\n",
    "\n",
    "    img_filmed_r, img_filmed_g, img_filmed_b = fourier_handler.split_RGB_2_Grayscale(\n",
    "        x_filmed)\n",
    "    img_clean_r, img_clean_g, img_clean_b = fourier_handler.split_RGB_2_Grayscale(\n",
    "        x_clean)\n",
    "\n",
    "    img_filmed_complex_r = fourier_handler.grayscale_2_Fourier(\n",
    "        img_filmed_r)\n",
    "    img_filmed_complex_g = fourier_handler.grayscale_2_Fourier(\n",
    "        img_filmed_g)\n",
    "    img_filmed_complex_b = fourier_handler.grayscale_2_Fourier(\n",
    "        img_filmed_b)\n",
    "\n",
    "    img_clean_complex_r = fourier_handler.grayscale_2_Fourier(\n",
    "        img_clean_r)\n",
    "    img_clean_complex_g = fourier_handler.grayscale_2_Fourier(\n",
    "        img_clean_g)\n",
    "    img_clean_complex_b = fourier_handler.grayscale_2_Fourier(\n",
    "        img_clean_b)\n",
    "\n",
    "\n",
    "    x_filmed_fourier_px, x_clean_fourier_px, differenzbild_fourier_px, img_filmed_fourier_combined, img_clean_fourier_combined = fourier_handler.generate_mask_from_images()\n",
    "    # plt.imsave(\".\\\\tmp\\\\img_filmed_fourier_combined.png\",\n",
    "    #            img_filmed_fourier_combined, cmap=\"gray\")\n",
    "    # plt.imsave(\".\\\\tmp\\\\img_clean_fourier_combined.png\",\n",
    "    #            img_clean_fourier_combined, cmap=\"gray\")\n",
    "    if show_intermediate_pics:\n",
    "        print(\"differenzbild_fourier_px: \")\n",
    "        # print(differenzbild_fourier_px)\n",
    "        plt.imshow(differenzbild_fourier_px, cmap=\"gray\")\n",
    "        plt.show()\n",
    "\n",
    "    differenzbild_fourier_px = differenzbild_fourier_px.reshape(\n",
    "        1, IMG_WIDTH, IMG_HEIGHT, 1)    \n",
    "\n",
    "\n",
    "\n",
    "    del(fourier_handler)\n",
    "\n",
    "\n",
    "\n",
    "    # ----------- HIER STARTET U-NET-MODEL -----------\n",
    "\n",
    "    u_net_output = execute_UNet_model(\n",
    "        differenzbild_fourier_px, training=True)\n",
    "\n",
    "\n",
    "    # print(\"u_net_output: \")\n",
    "    # print(u_net_output)\n",
    "\n",
    "    # ----------- ALPHA-BLENDING -----------\n",
    "\n",
    "\n",
    "    # CASTING IST NICHT ABLEITBAR - KANN MAN NICHT VERWENDEN!!\n",
    "    # u_net_output = tf.cast(u_net_output, tf.int32)\n",
    "    # u_net_output = tf.cast(u_net_output, tf.bool)\n",
    "\n",
    "    # FORMEL: (1 - out) * clean + out * filmed\n",
    "    # t2c -> transfered to complex\n",
    "\n",
    "\n",
    "    if show_intermediate_pics:\n",
    "        print(\"x_clean: \")\n",
    "        plt.imshow(x_clean)\n",
    "        plt.show()\n",
    "\n",
    "        print(\"x_filmed: \")\n",
    "        plt.imshow(x_filmed)\n",
    "        plt.show()\n",
    "\n",
    "    x_clean = x_clean.reshape((1, IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "    x_filmed = x_filmed.reshape((1, IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "\n",
    "\n",
    "\n",
    "    u_net_output = tf.reshape(\n",
    "        u_net_output, shape=(IMG_WIDTH, IMG_HEIGHT))\n",
    "\n",
    "    img_clean_complex_r = img_clean_complex_r.reshape((1, IMG_WIDTH, IMG_HEIGHT, 1))\n",
    "    img_clean_complex_g = img_clean_complex_g.reshape((1, IMG_WIDTH, IMG_HEIGHT, 1))\n",
    "    img_clean_complex_b = img_clean_complex_b.reshape((1, IMG_WIDTH, IMG_HEIGHT, 1))\n",
    "    img_filmed_complex_r = img_filmed_complex_r.reshape((1, IMG_WIDTH, IMG_HEIGHT, 1))\n",
    "    img_filmed_complex_g = img_filmed_complex_g.reshape((1, IMG_WIDTH, IMG_HEIGHT, 1))\n",
    "    img_filmed_complex_b = img_filmed_complex_b.reshape((1, IMG_WIDTH, IMG_HEIGHT, 1))\n",
    "\n",
    "    # ------------ postprocessing Model aufrufen --------\n",
    "\n",
    "    image_processed_rgb = execute_postprocessing_model([\n",
    "        x_clean ,\n",
    "        x_filmed ,\n",
    "        u_net_output,\n",
    "        img_clean_complex_r ,\n",
    "        img_clean_complex_g ,\n",
    "        img_clean_complex_b ,\n",
    "        img_filmed_complex_r ,\n",
    "        img_filmed_complex_g ,\n",
    "        img_filmed_complex_b ,\n",
    "    ])\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    if show_intermediate_pics:\n",
    "        print(\"image_processed_rgb: \")\n",
    "        # print(np.array(image_processed_rgb).reshape(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "        plt.imshow(np.array(image_processed_rgb).reshape(\n",
    "            IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    # ----------- Feed multiple Buckets in CNN for predicting amount of alias -----------\n",
    "\n",
    "    def create_multiple_buckets_to_feed_them_into_CNN(tensor):\n",
    "\n",
    "        BATCH_SIZE_CNN = 1\n",
    "        NUM_BOXES = 30\n",
    "        CROP_SIZE = (60, 60)\n",
    "\n",
    "        boxes = tf.random.uniform(shape=(NUM_BOXES, 4))\n",
    "        box_indices = tf.random.uniform(shape=(NUM_BOXES,), minval=0,\n",
    "                                        maxval=BATCH_SIZE_CNN, dtype=tf.int32)\n",
    "        \n",
    "        output = tf.image.crop_and_resize(\n",
    "            tensor, boxes, box_indices, CROP_SIZE)\n",
    "        return output\n",
    "\n",
    "    cnn_input = create_multiple_buckets_to_feed_them_into_CNN(image_processed_rgb)\n",
    "\n",
    "    # print(\"cnn_input: \")\n",
    "    # print(cnn_input)\n",
    "\n",
    "\n",
    "\n",
    "    # ------- Make prediction --------\n",
    "\n",
    "    y_pred = execute_cnn_model(cnn_input)\n",
    "\n",
    "    y_pred = tf.math.reduce_mean(\n",
    "        y_pred, keepdims=True\n",
    "    )\n",
    "\n",
    "    # print(\"Ende von calc_mean_aias_value_of_one_image:\")\n",
    "    # print(\"y_pred: \")\n",
    "    # print(y_pred)\n",
    "\n",
    "    return y_pred, differenzbild_fourier_px, u_net_output, image_processed_rgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   0%|                                  | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next batch...\n",
      "WARNING:tensorflow:Model was constructed with shape (1, 128, 128) for input KerasTensor(type_spec=TensorSpec(shape=(1, 128, 128), dtype=tf.float32, name='input_394'), name='input_394', description=\"created by layer 'input_394'\"), but it was called on an input with incompatible shape (128, 128).\n",
      "cnn_mean_prediction_values.shape: \n",
      "(32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   3%|▊                         | 1/32 [00:40<20:58, 40.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- epoch_loss: 0.1877157986164093\n",
      "next batch...\n",
      "cnn_mean_prediction_values.shape: \n",
      "(32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   6%|█▋                        | 2/32 [01:23<20:55, 41.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- epoch_loss: 0.2320530265569687\n",
      "next batch...\n",
      "cnn_mean_prediction_values.shape: \n",
      "(32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   9%|██▍                       | 3/32 [02:05<20:13, 41.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- epoch_loss: 0.1947370171546936\n",
      "next batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   9%|██▍                       | 3/32 [02:07<20:30, 42.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------Am Ende angelangt, gehe in neue Epoche\n",
      "Start of epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   0%|                                  | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next batch...\n",
      "cnn_mean_prediction_values.shape: \n",
      "(32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   3%|▊                         | 1/32 [00:39<20:12, 39.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- epoch_loss: 0.18490536510944366\n",
      "next batch...\n",
      "cnn_mean_prediction_values.shape: \n",
      "(32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   6%|█▋                        | 2/32 [01:18<19:31, 39.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- epoch_loss: 0.17968514561653137\n",
      "next batch...\n",
      "cnn_mean_prediction_values.shape: \n",
      "(32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   9%|██▍                       | 3/32 [01:57<18:55, 39.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- epoch_loss: 0.16602391004562378\n",
      "next batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   9%|██▍                       | 3/32 [01:59<19:10, 39.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------Am Ende angelangt, gehe in neue Epoche\n",
      "Start of epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   0%|                                  | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next batch...\n",
      "cnn_mean_prediction_values.shape: \n",
      "(32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   3%|▊                         | 1/32 [00:38<20:07, 38.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- epoch_loss: 0.15996205806732178\n",
      "next batch...\n",
      "cnn_mean_prediction_values.shape: \n",
      "(32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   6%|█▋                        | 2/32 [01:17<19:28, 38.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- epoch_loss: 0.15648908913135529\n",
      "next batch...\n",
      "cnn_mean_prediction_values.shape: \n",
      "(32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   9%|██▍                       | 3/32 [01:56<18:47, 38.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- epoch_loss: 0.1500517874956131\n",
      "next batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   9%|██▍                       | 3/32 [01:58<19:04, 39.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------Am Ende angelangt, gehe in neue Epoche\n",
      "Start of epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   0%|                                  | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next batch...\n",
      "cnn_mean_prediction_values.shape: \n",
      "(32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   3%|▊                         | 1/32 [00:39<20:17, 39.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- epoch_loss: 0.14458820223808289\n",
      "next batch...\n",
      "cnn_mean_prediction_values.shape: \n",
      "(32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   6%|█▋                        | 2/32 [01:17<19:25, 38.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- epoch_loss: 0.13556121289730072\n",
      "next batch...\n",
      "cnn_mean_prediction_values.shape: \n",
      "(32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   9%|██▍                       | 3/32 [01:56<18:41, 38.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- epoch_loss: 0.12614379823207855\n",
      "next batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   9%|██▍                       | 3/32 [01:57<19:00, 39.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------Am Ende angelangt, gehe in neue Epoche\n",
      "Start of epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   0%|                                  | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next batch...\n",
      "cnn_mean_prediction_values.shape: \n",
      "(32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   3%|▊                         | 1/32 [00:39<20:09, 39.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- epoch_loss: 0.11701855063438416\n",
      "next batch...\n",
      "cnn_mean_prediction_values.shape: \n",
      "(32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   6%|█▋                        | 2/32 [01:17<19:27, 38.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- epoch_loss: 0.11009073257446289\n",
      "next batch...\n",
      "cnn_mean_prediction_values.shape: \n",
      "(32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   9%|██▍                       | 3/32 [01:56<18:44, 38.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- epoch_loss: 0.10328672081232071\n",
      "next batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   9%|██▍                       | 3/32 [01:58<19:02, 39.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------Am Ende angelangt, gehe in neue Epoche\n",
      "Start of epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   0%|                                  | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next batch...\n",
      "cnn_mean_prediction_values.shape: \n",
      "(32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   3%|▊                         | 1/32 [00:39<20:37, 39.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- epoch_loss: 0.09712711721658707\n",
      "next batch...\n",
      "cnn_mean_prediction_values.shape: \n",
      "(32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   6%|█▋                        | 2/32 [01:18<19:33, 39.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- epoch_loss: 0.09192581474781036\n",
      "next batch...\n",
      "cnn_mean_prediction_values.shape: \n",
      "(32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   9%|██▍                       | 3/32 [01:57<18:49, 38.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- epoch_loss: 0.08705170452594757\n",
      "next batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   9%|██▍                       | 3/32 [01:58<19:10, 39.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------Am Ende angelangt, gehe in neue Epoche\n",
      "Start of epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   0%|                                  | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next batch...\n",
      "cnn_mean_prediction_values.shape: \n",
      "(32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   3%|▊                         | 1/32 [00:38<20:06, 38.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- epoch_loss: 0.08255166560411453\n",
      "next batch...\n",
      "cnn_mean_prediction_values.shape: \n",
      "(32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   6%|█▋                        | 2/32 [01:17<19:25, 38.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- epoch_loss: 0.07855840027332306\n",
      "next batch...\n",
      "cnn_mean_prediction_values.shape: \n",
      "(32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   9%|██▍                       | 3/32 [01:59<19:20, 40.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- epoch_loss: 0.07495899498462677\n",
      "next batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   9%|██▍                       | 3/32 [02:00<19:28, 40.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------Am Ende angelangt, gehe in neue Epoche\n",
      "Start of epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   0%|                                  | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next batch...\n",
      "cnn_mean_prediction_values.shape: \n",
      "(32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   3%|▊                         | 1/32 [00:42<21:47, 42.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- epoch_loss: 0.071656234562397\n",
      "next batch...\n",
      "cnn_mean_prediction_values.shape: \n",
      "(32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   6%|█▋                        | 2/32 [01:23<20:55, 41.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- epoch_loss: 0.06857957690954208\n",
      "next batch...\n",
      "cnn_mean_prediction_values.shape: \n",
      "(32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   9%|██▍                       | 3/32 [02:05<20:11, 41.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- epoch_loss: 0.06573917716741562\n",
      "next batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   9%|██▍                       | 3/32 [02:07<20:29, 42.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------Am Ende angelangt, gehe in neue Epoche\n",
      "Start of epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   0%|                                  | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next batch...\n",
      "cnn_mean_prediction_values.shape: \n",
      "(32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   3%|▊                         | 1/32 [00:41<21:26, 41.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- epoch_loss: 0.06320249289274216\n",
      "next batch...\n",
      "cnn_mean_prediction_values.shape: \n",
      "(32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   6%|█▋                        | 2/32 [01:23<20:54, 41.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- epoch_loss: 0.06094885617494583\n",
      "next batch...\n",
      "cnn_mean_prediction_values.shape: \n",
      "(32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   9%|██▍                       | 3/32 [02:05<20:08, 41.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- epoch_loss: 0.058876607567071915\n",
      "next batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   9%|██▍                       | 3/32 [02:06<20:25, 42.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------Am Ende angelangt, gehe in neue Epoche\n",
      "Start of epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   0%|                                  | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next batch...\n",
      "cnn_mean_prediction_values.shape: \n",
      "(32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   3%|▊                         | 1/32 [00:42<21:42, 42.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- epoch_loss: 0.07108059525489807\n",
      "next batch...\n",
      "cnn_mean_prediction_values.shape: \n",
      "(32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   6%|█▋                        | 2/32 [01:23<20:50, 41.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- epoch_loss: 0.07282759249210358\n",
      "next batch...\n",
      "cnn_mean_prediction_values.shape: \n",
      "(32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   9%|██▍                       | 3/32 [02:05<20:10, 41.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- epoch_loss: 0.07128407061100006\n",
      "next batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   9%|██▍                       | 3/32 [02:07<20:27, 42.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------Am Ende angelangt, gehe in neue Epoche\n",
      "Start of epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   0%|                                  | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next batch...\n",
      "cnn_mean_prediction_values.shape: \n",
      "(32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   3%|▊                         | 1/32 [00:41<21:37, 41.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- epoch_loss: 0.06988238543272018\n",
      "next batch...\n",
      "cnn_mean_prediction_values.shape: \n",
      "(32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   6%|█▋                        | 2/32 [01:23<20:51, 41.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- epoch_loss: 0.06852805614471436\n",
      "next batch...\n",
      "cnn_mean_prediction_values.shape: \n",
      "(32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   9%|██▍                       | 3/32 [02:04<20:03, 41.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- epoch_loss: 0.06725845485925674\n",
      "next batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   9%|██▍                       | 3/32 [02:06<20:22, 42.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------Am Ende angelangt, gehe in neue Epoche\n",
      "Start of epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   0%|                                  | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next batch...\n",
      "cnn_mean_prediction_values.shape: \n",
      "(32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   0%|                                  | 0/32 [00:34<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Main\\MA_PROGR\\Code_Fourier\\UNet_for_Fourier.ipynb Cell 23'\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Main/MA_PROGR/Code_Fourier/UNet_for_Fourier.ipynb#ch0000022?line=115'>116</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(y_true\u001b[39m=\u001b[39my_true, y_pred\u001b[39m=\u001b[39mcnn_mean_prediction_values)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Main/MA_PROGR/Code_Fourier/UNet_for_Fourier.ipynb#ch0000022?line=116'>117</a>\u001b[0m \u001b[39m# print(\"loss: \")\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Main/MA_PROGR/Code_Fourier/UNet_for_Fourier.ipynb#ch0000022?line=117'>118</a>\u001b[0m \u001b[39m# print(loss)\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/Main/MA_PROGR/Code_Fourier/UNet_for_Fourier.ipynb#ch0000022?line=119'>120</a>\u001b[0m gradients \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39;49mgradient(loss, model_u_net\u001b[39m.\u001b[39;49mtrainable_weights)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Main/MA_PROGR/Code_Fourier/UNet_for_Fourier.ipynb#ch0000022?line=120'>121</a>\u001b[0m \u001b[39mdel\u001b[39;00m cnn_mean_prediction_values[:]\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Main/MA_PROGR/Code_Fourier/UNet_for_Fourier.ipynb#ch0000022?line=121'>122</a>\u001b[0m \u001b[39m# print(\"gradients: \")\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Main/MA_PROGR/Code_Fourier/UNet_for_Fourier.ipynb#ch0000022?line=122'>123</a>\u001b[0m \u001b[39m# print(gradients)\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Main/MA_PROGR/Code_Fourier/UNet_for_Fourier.ipynb#ch0000022?line=123'>124</a>\u001b[0m \n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Main/MA_PROGR/Code_Fourier/UNet_for_Fourier.ipynb#ch0000022?line=124'>125</a>\u001b[0m \u001b[39m# Optimize the model:\u001b[39;00m\n",
      "File \u001b[1;32md:\\Programme\\Anaconda3\\envs\\tf_training\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1074\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/backprop.py?line=1069'>1070</a>\u001b[0m \u001b[39mif\u001b[39;00m output_gradients \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/backprop.py?line=1070'>1071</a>\u001b[0m   output_gradients \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m ops\u001b[39m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/backprop.py?line=1071'>1072</a>\u001b[0m                       \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m nest\u001b[39m.\u001b[39mflatten(output_gradients)]\n\u001b[1;32m-> <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/backprop.py?line=1073'>1074</a>\u001b[0m flat_grad \u001b[39m=\u001b[39m imperative_grad\u001b[39m.\u001b[39;49mimperative_grad(\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/backprop.py?line=1074'>1075</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tape,\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/backprop.py?line=1075'>1076</a>\u001b[0m     flat_targets,\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/backprop.py?line=1076'>1077</a>\u001b[0m     flat_sources,\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/backprop.py?line=1077'>1078</a>\u001b[0m     output_gradients\u001b[39m=\u001b[39;49moutput_gradients,\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/backprop.py?line=1078'>1079</a>\u001b[0m     sources_raw\u001b[39m=\u001b[39;49mflat_sources_raw,\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/backprop.py?line=1079'>1080</a>\u001b[0m     unconnected_gradients\u001b[39m=\u001b[39;49munconnected_gradients)\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/backprop.py?line=1081'>1082</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent:\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/backprop.py?line=1082'>1083</a>\u001b[0m   \u001b[39m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/backprop.py?line=1083'>1084</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_watched_variables \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tape\u001b[39m.\u001b[39mwatched_variables()\n",
      "File \u001b[1;32md:\\Programme\\Anaconda3\\envs\\tf_training\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:71\u001b[0m, in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/imperative_grad.py?line=66'>67</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m     <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/imperative_grad.py?line=67'>68</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/imperative_grad.py?line=68'>69</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mUnknown value for unconnected_gradients: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m unconnected_gradients)\n\u001b[1;32m---> <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/imperative_grad.py?line=70'>71</a>\u001b[0m \u001b[39mreturn\u001b[39;00m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_TapeGradient(\n\u001b[0;32m     <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/imperative_grad.py?line=71'>72</a>\u001b[0m     tape\u001b[39m.\u001b[39;49m_tape,  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m     <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/imperative_grad.py?line=72'>73</a>\u001b[0m     target,\n\u001b[0;32m     <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/imperative_grad.py?line=73'>74</a>\u001b[0m     sources,\n\u001b[0;32m     <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/imperative_grad.py?line=74'>75</a>\u001b[0m     output_gradients,\n\u001b[0;32m     <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/imperative_grad.py?line=75'>76</a>\u001b[0m     sources_raw,\n\u001b[0;32m     <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/imperative_grad.py?line=76'>77</a>\u001b[0m     compat\u001b[39m.\u001b[39;49mas_str(unconnected_gradients\u001b[39m.\u001b[39;49mvalue))\n",
      "File \u001b[1;32md:\\Programme\\Anaconda3\\envs\\tf_training\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1302\u001b[0m, in \u001b[0;36m_TapeGradientFunctions._wrap_backward_function.<locals>._backward_function_wrapper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=1299'>1300</a>\u001b[0m   \u001b[39mif\u001b[39;00m input_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m backward_function_inputs:\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=1300'>1301</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m-> <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=1301'>1302</a>\u001b[0m \u001b[39mreturn\u001b[39;00m backward\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=1302'>1303</a>\u001b[0m     processed_args, remapped_captures)\n",
      "File \u001b[1;32md:\\Programme\\Anaconda3\\envs\\tf_training\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1960\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=1955'>1956</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=1956'>1957</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=1957'>1958</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=1958'>1959</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=1959'>1960</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=1960'>1961</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=1961'>1962</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=1962'>1963</a>\u001b[0m     args,\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=1963'>1964</a>\u001b[0m     possible_gradient_type,\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=1964'>1965</a>\u001b[0m     executing_eagerly)\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=1965'>1966</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\Programme\\Anaconda3\\envs\\tf_training\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=588'>589</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=589'>590</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=590'>591</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=591'>592</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=592'>593</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=593'>594</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=594'>595</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=595'>596</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=596'>597</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=597'>598</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=598'>599</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=599'>600</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=602'>603</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=603'>604</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32md:\\Programme\\Anaconda3\\envs\\tf_training\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/execute.py?line=57'>58</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/execute.py?line=58'>59</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/execute.py?line=59'>60</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/execute.py?line=60'>61</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/execute.py?line=61'>62</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Custom train loop\n",
    "\n",
    "SAFE_RESULTS = True\n",
    "WRITE_PATH = \"D:\\\\Main\\\\MA_PROGR\\\\Data\\\\UNET_Output\\\\Session04\"\n",
    "\n",
    "show_intermediate_pics = False\n",
    "\n",
    "RGB_WEIGHTS = [0.299, 0.587, 0.114]\n",
    "\n",
    "\n",
    "overall_train_loss = []\n",
    "\n",
    "\n",
    "execute_UNet_model = tf.function(model_u_net)\n",
    "execute_cnn_model = tf.function(model_cnn)\n",
    "execute_postprocessing_model = tf.function(postprocessing_model)\n",
    "\n",
    "NUM_EPOCHS = 15\n",
    "batch_size_cnn = 1\n",
    "batch_size_unet = 32\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "# loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "loss_fn = tf.keras.losses.MeanAbsoluteError()\n",
    "# loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "epoch_loss = tf.keras.metrics.MeanAbsoluteError()\n",
    "# epoch_loss = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "# epoch_loss = tf.keras.metrics.SparseCategoricalCrossentropy()\n",
    "\n",
    "train_writer = tf.summary.create_file_writer(\"u_net_logs/train/\")\n",
    "test_writer = tf.summary.create_file_writer(\"u_net_logs/test/\")\n",
    "\n",
    "y_true = tf.constant(0, dtype=tf.float16, name=\"y_true\")\n",
    "\n",
    "jump_to_new_epoch = False\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    print(f\"Start of epoch {epoch}\")\n",
    "    jump_to_new_epoch = False\n",
    "\n",
    "    # Mache neue Generater, sodass wieder durch alle Bilder durchgegange wird für die nächste Epoche:\n",
    "    train_filmed_img_gen_obj = my_train_filmed_gen()\n",
    "    train_clean_img_gen_obj = my_train_clean_gen()\n",
    "\n",
    "    # ---------------------------------------------------------------------------- BATCHES SAMMELN Start ----------------------------------------------------------------------------------------\n",
    "    train_step = 0\n",
    "\n",
    "    for batch_idx in tqdm(range(batch_size_unet), desc=\"training...\", ascii=False, ncols=75):\n",
    "        print(\"next batch...\")\n",
    "        cnn_mean_prediction_values = []\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "        \n",
    "            # Bilder für den nächsten Batch sammeln:\n",
    "            for i in range(batch_size_unet):\n",
    "                try:\n",
    "                    x_filmed = train_filmed_img_gen_obj.__next__()\n",
    "                    x_clean = train_clean_img_gen_obj.__next__()\n",
    "                except StopIteration as e:\n",
    "                    print(\"------------------------Am Ende angelangt, gehe in neue Epoche\")\n",
    "\n",
    "                    jump_to_new_epoch = True\n",
    "\n",
    "                if jump_to_new_epoch == True:\n",
    "                    # Alle Bilder sind aufgebraucht, gehe in neue Epoche\n",
    "                    break\n",
    "\n",
    "\n",
    "                \n",
    "                y_pred, differenzbild_fourier_px, u_net_output, image_processed_rgb = calc_mean_alias_value_of_one_image(\n",
    "                    x_filmed, x_clean)\n",
    "                cnn_mean_prediction_values.append(y_pred)\n",
    "\n",
    "                # print(\"y_pred: \")\n",
    "                # print(y_pred)\n",
    "\n",
    "                # ---------------------------------------------------------------------------- BATCHES SAMMELN ENDE ----------------------------------------------------------------------------------------\n",
    "\n",
    "            \n",
    "            if SAFE_RESULTS:\n",
    "                plt.imsave(f\"{WRITE_PATH}\\\\x_filmed_{epoch}_{batch_idx}.png\", x_filmed)\n",
    "\n",
    "                plt.imsave(f\"{WRITE_PATH}\\\\differenzbild_{epoch}_{batch_idx}.png\",\n",
    "                   differenzbild_fourier_px.reshape((IMG_WIDTH,IMG_HEIGHT)), cmap=\"gray\")\n",
    "\n",
    "                plt.imsave(f\"{WRITE_PATH}\\\\unet_output_{epoch}_{batch_idx}.png\",\n",
    "                   u_net_output, cmap=\"gray\")\n",
    "\n",
    "\n",
    "                # Umformen in Numpy-Array\n",
    "                image_processed_rgb = np.array(image_processed_rgb).reshape((IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "\n",
    "                # Max-Wert liegt manchesmal über 1 (keine ahnung warum...)\n",
    "                if image_processed_rgb.max() >= 1:\n",
    "                    # Werte auf 0 - 1 bringen\n",
    "                    image_processed_rgb= image_processed_rgb / image_processed_rgb.max()\n",
    "\n",
    "\n",
    "                plt.imsave(f\"{WRITE_PATH}\\\\image_processed_rgb_{epoch}_{batch_idx}.png\",\n",
    "                   np.array(image_processed_rgb).reshape((IMG_WIDTH, IMG_HEIGHT, 3)))\n",
    "\n",
    "            if jump_to_new_epoch == True:\n",
    "                # Alle Bilder sind aufgebraucht, gehe in neue \n",
    "                break\n",
    "\n",
    "            # ----------- Calc loss -----------\n",
    "\n",
    "            y_true = tf.zeros(batch_size_unet, 1)\n",
    "\n",
    "            # print(\"cnn_mean_prediction_values.shape: \")\n",
    "            # print( np.array(cnn_mean_prediction_values).shape)\n",
    "\n",
    "            loss = loss_fn(y_true=y_true, y_pred=cnn_mean_prediction_values)\n",
    "            # print(\"loss: \")\n",
    "            # print(loss)\n",
    "\n",
    "            gradients = tape.gradient(loss, model_u_net.trainable_weights)\n",
    "            del cnn_mean_prediction_values[:]\n",
    "            # print(\"gradients: \")\n",
    "            # print(gradients)\n",
    "\n",
    "            # Optimize the model:\n",
    "            optimizer.apply_gradients(\n",
    "                zip(gradients, model_u_net.trainable_variables))\n",
    "\n",
    "            tmp = epoch_loss.update_state(y_true, y_pred)\n",
    "\n",
    "            # print(\"tmp\")\n",
    "            # print(tmp)\n",
    "\n",
    "\n",
    "            # print(\"------------------------------------\")\n",
    "            # print(\"y_true:\")\n",
    "            # print(y_true)\n",
    "\n",
    "            # print(\"y_pred\")\n",
    "            # print(y_pred)\n",
    "            # print(\"------------------------------------\")\n",
    "\n",
    "\n",
    "\n",
    "            # with train_writer.as_default():\n",
    "            #     tf.summary.scalar(\"Loss\", loss, step=train_step)\n",
    "            #     tf.summary.scalar(\n",
    "            #         \"Accuracy\", epoch_loss.result(), step=train_step,\n",
    "            #     )\n",
    "            # train_step += 1\n",
    "        \n",
    "        # End Epoch\n",
    "\n",
    "        print(f\"--------------- epoch_loss: {epoch_loss.result()}\")\n",
    "        overall_train_loss.append(epoch_loss.result())\n",
    "\n",
    "\n",
    "\n",
    "# overall_train_loss = epoch_loss.result()\n",
    "# print(f\"overall_train_loss: {overall_train_loss}\")\n",
    "# epoch_loss.reset_states()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22306945b80>]"
      ]
     },
     "execution_count": 729,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(overall_train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
    "fig.suptitle('Training Metrics')\n",
    "\n",
    "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
    "axes[0].plot(overall_train_loss)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 65536 into shape (1,128,128,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Main\\MA_PROGR\\Code_Fourier\\UNet_for_Fourier.ipynb Cell 24'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Main/MA_PROGR/Code_Fourier/UNet_for_Fourier.ipynb#ch0000022?line=0'>1</a>\u001b[0m test_img \u001b[39m=\u001b[39m img[\u001b[39m400\u001b[39m:\u001b[39m528\u001b[39m, \u001b[39m400\u001b[39m:\u001b[39m528\u001b[39m,:]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Main/MA_PROGR/Code_Fourier/UNet_for_Fourier.ipynb#ch0000022?line=1'>2</a>\u001b[0m test_img \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray(test_img)\u001b[39m.\u001b[39;49mreshape(\u001b[39m1\u001b[39;49m, \u001b[39m128\u001b[39;49m , \u001b[39m128\u001b[39;49m , \u001b[39m3\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Main/MA_PROGR/Code_Fourier/UNet_for_Fourier.ipynb#ch0000022?line=3'>4</a>\u001b[0m \u001b[39m# plt.imshow(test_img)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Main/MA_PROGR/Code_Fourier/UNet_for_Fourier.ipynb#ch0000022?line=5'>6</a>\u001b[0m test_img\u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconvert_to_tensor(test_img, dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mfloat32)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 65536 into shape (1,128,128,3)"
     ]
    }
   ],
   "source": [
    "test_img = img[400:528, 400:528,:]\n",
    "test_img = np.array(test_img).reshape(1, 128 , 128 , 3)\n",
    "\n",
    "# plt.imshow(test_img)\n",
    "\n",
    "test_img= tf.convert_to_tensor(test_img, dtype=tf.float32)\n",
    "\n",
    "test_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22300133f10>"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "BATCH_SIZE = 1\n",
    "NUM_BOXES = 3\n",
    "IMAGE_HEIGHT = 128\n",
    "IMAGE_WIDTH = 128\n",
    "CHANNELS = 3\n",
    "CROP_SIZE = (24, 24)\n",
    "\n",
    "test_img = img[400:528, 400:528, :]\n",
    "test_img = np.array(test_img).reshape(1, 128, 128, 3)\n",
    "\n",
    "# plt.imshow(test_img)\n",
    "\n",
    "test_img = tf.convert_to_tensor(test_img, dtype=tf.float32)\n",
    "image = test_img\n",
    "boxes = tf.random.uniform(shape=(NUM_BOXES, 4))\n",
    "# plt.imshow(np.array(image).reshape(IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS))\n",
    "# plt.show()\n",
    "box_indices = tf.random.uniform(shape=(NUM_BOXES,), minval=0,\n",
    "                                maxval=BATCH_SIZE, dtype=tf.int32)\n",
    "output = tf.image.crop_and_resize(image, boxes, box_indices, CROP_SIZE)\n",
    "output.shape  # => (5, 24, 24, 3)\n",
    "\n",
    "plt.imshow(output[2])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bbe6f1f0ffae94815f8b68c5970304948992b116503ec65631f55d524065bfaa"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tf_training')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
